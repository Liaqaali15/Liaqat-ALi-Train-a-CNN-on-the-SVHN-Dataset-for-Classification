{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4f6e0339-71e2-43f5-98c1-d6bccbc89acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd85892-08dc-4ba6-ac67-d5a174bc98b6",
   "metadata": {},
   "source": [
    "1. import warnings: \n",
    "\n",
    "- This line imports Python’s warnings module. \n",
    "- The warnings module helps manage warning messages that may appear during code execution.\n",
    "- Instead of stopping the program, warnings notify users of potential issues.\n",
    "- This can include deprecated features, resource usage, or minor errors.\n",
    "- It’s useful for debugging or improving code without interrupting execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "68835050-c56d-4790-93a2-338147f0c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d7bb75-19d0-41e6-8f14-fdcdb128205c",
   "metadata": {},
   "source": [
    "This line imports Python’s built-in os module.\n",
    "The os module provides functions for interacting with the operating system.\n",
    "It allows us to handle files, directories, and system paths.\n",
    "Using os, we can read or write files, create directories, and navigate file structures.\n",
    "It’s essential for tasks that need to interact with the system’s file structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3447313c-6bbf-4543-a411-e833e729775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08f410b-deb7-42e0-a772-fc1cd2240285",
   "metadata": {},
   "source": [
    "- This line imports the pandas library and gives it the alias pd.\n",
    "- pandas is a powerful library for data manipulation and analysis.\n",
    "- It allows handling of structured data using DataFrames and Series objects.\n",
    "- With pd, you can read, write, filter, and analyze data easily.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5f09e07-bde4-4693-b9a8-367de33d59bf",
   "metadata": {},
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4843bdb0-141e-4bfd-a5a7-ba6c962b5593",
   "metadata": {},
   "source": [
    "- This line imports the numpy library and gives it the alias np.\n",
    "- numpy is essential for numerical computations in Python.\n",
    "- It provides tools for working with arrays, matrices, and mathematical functions.\n",
    "- np enables efficient handling of large datasets and complex operations.\n",
    "- The shorthand (np) makes code more concise and widely recognized in data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "747569bf-0147-42e1-b1c5-b0a2cbb6c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    " import matplotlib.pyplot as plt\n",
    " %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f6295d-ea0a-4dc7-b9bf-4a8b863b04dd",
   "metadata": {},
   "source": [
    "- The first line imports matplotlib.pyplot with the alias plt.\n",
    "- matplotlib.pyplot is a plotting library for creating graphs and visualizations.\n",
    "- plt provides functions for line plots, bar charts, histograms, etc.\n",
    "- The %matplotlib inline command is a Jupyter Notebook-specific “magic” command.\n",
    "- It ensures that plots display directly within the notebook for easy viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2f67559-83b2-46f0-90af-03ea04607cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    " from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1399a8-20f1-48ce-86b2-c0ab07b1315a",
   "metadata": {},
   "source": [
    "7. from matplotlib import pyplot\n",
    "\n",
    "- This line imports the pyplot module directly from matplotlib.\n",
    "- pyplot provides functions for creating a variety of plots and visualizations.\n",
    "- It works similarly to matplotlib.pyplot but allows direct usage without the plt alias.\n",
    "- Each function in pyplot corresponds to a different type of plot component (e.g., plot(), show()).\n",
    "- This import style is less common but can be useful if plt aliasing isn’t needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3b838b09-b76d-4cd6-909a-a4adec2ca8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4db216-264a-44b4-9d2b-2db3e1d11a92",
   "metadata": {},
   "source": [
    "8. import seaborn as sns\n",
    "\n",
    "- This line imports the seaborn library with the alias sns.\n",
    "- seaborn is a data visualization library based on matplotlib.\n",
    "- It provides a high-level interface for creating attractive, informative statistical graphics.\n",
    "- sns offers functions for complex visualizations like heatmaps, .\n",
    "- The alias (sns) is standard and makes code involving seaborn more concise and readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06a63556-6382-4138-8275-8e614c6b6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2145f3-4f6a-4fee-8d80-52065c656251",
   "metadata": {},
   "source": [
    "9. import tensorflow\n",
    "\n",
    "- This line imports the tensorflow library, an open-source framework for machine learning and deep learning.\n",
    "- tensorflow provides tools for building and training neural networks, including deep CNNs, RNNs, and more.\n",
    "- It supports both low-level operations (like tensors) and high-level APIs (like Keras) for model building.\n",
    "- The library is widely used for tasks like image recognition, natural language processing, and predictive analytics.\n",
    "- tensorflow enables deployment on various platforms, including mobile, servers, and cloud environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a844816b-3a81-435c-b03f-ae75592b3673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff93dfb-a764-4100-bdf4-7d3a0cbff82a",
   "metadata": {},
   "source": [
    "print the version of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "309d08cc-226c-4287-9d99-4d51e21d6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    " warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf117b1-41c2-486d-8747-4d66c5d25746",
   "metadata": {},
   "source": [
    "10. warnings.filterwarnings('ignore'):\n",
    "\n",
    "- This line configures the warnings module to suppress all warning messages.\n",
    "- By setting this filter to 'ignore', the program will not display warnings during execution.\n",
    "- This can be useful for cleaner output, especially when running code where warnings are expected.\n",
    "- However, ignoring warnings can lead to missing important alerts about potential issues.\n",
    "- It's often used in exploratory data analysis or during development to reduce clutter in the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c88b0306-6a45-4107-8055-cf70ae6a3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc429136-ad06-466a-96de-5f12633ab615",
   "metadata": {},
   "source": [
    "11. pd.options.display.max_columns = None:\n",
    "\n",
    "- This line sets the maximum number of columns displayed in a pandas DataFrame to None.\n",
    "- By doing so, it allows all columns to be shown when printing a DataFrame, regardless of how many there are.\n",
    "- This is helpful for viewing wide DataFrames without truncation.\n",
    "- Adjusting display options improves data inspection and analysis in the console.\n",
    "- It enhances readability, especially when working with datasets that have many features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "219091c5-4bbb-4715-95eb-a2ca09bb21d7",
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.options.display.float_format='{:.7f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eda99db-4d54-4825-b627-ab34fe754c20",
   "metadata": {},
   "source": [
    "12. pd.options.display.float_format = '{:.7f}'.format:\n",
    "\n",
    "- This line sets the format for displaying floating-point numbers in pandas DataFrames.\n",
    "- By specifying '{:.7f}'.format, it configures pandas to show numbers with seven decimal places.\n",
    "- This is useful for maintaining consistency and precision in numerical outputs.\n",
    "- It improves readability when analyzing data with many decimal values.\n",
    "- Adjusting the float format can help in presentations or reports where specific precision is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d34a63dc-17c2-4362-9f37-12a889821049",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214ba73b-c480-4af3-b2e0-dc2de73dc23f",
   "metadata": {},
   "source": [
    "13. pd.options.display.max_rows = None:\n",
    "\n",
    "- This line sets the maximum number of rows displayed in a pandas DataFrame to None.\n",
    "- As a result, all rows will be shown when printing a DataFrame, regardless of the total count.\n",
    "- This is particularly useful for inspecting large datasets without truncation.\n",
    "- It enhances data visibility and allows thorough examination during analysis.\n",
    "- However, displaying too many rows can clutter the output, so use it judiciously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bc823f74-8adf-4d63-b796-84c5b8d03875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e815fc3-b3c4-4af0-b818-a4128bb2f7ad",
   "metadata": {},
   "source": [
    "14. import h5py:\n",
    "\n",
    "- This line imports the h5py library, which is used for handling HDF5 files in Python.\n",
    "- HDF5 (Hierarchical Data Format version 5) is a file format designed to store large amounts of data.\n",
    "- The h5py library provides an interface to read, write, and manipulate HDF5 files seamlessly.\n",
    "- It's commonly used in data science and machine learning for storing large datasets, including tensors and models.\n",
    "- By using h5py, you can efficiently manage data storage, allowing for quick access and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b0f0887f-6980-43e3-9588-030a4a2f923e",
   "metadata": {},
   "outputs": [],
   "source": [
    " h5f=h5py.File('Autonomous_Vehicles_SVHN_single_grey1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d7d581-5762-4ce9-8e01-1691d1ca0c0b",
   "metadata": {},
   "source": [
    "15. h5f = h5py.File('Autonomous_Vehicles_SVHN_single_grey1.h5'):\n",
    "- This line opens an HDF5 file named 'Autonomous_Vehicles_SVHN_single_grey1.h5' for reading and writing.\n",
    "- The h5py.File() function creates a file object (h5f) that allows interaction with the contents of the HDF5 file.\n",
    "- If the file exists, it loads the data; if not, it raises an error.\n",
    "- This file likely contains datasets related to autonomous vehicles, possibly images or labels.\n",
    "- Once opened, you can access datasets and metadata stored within the file using the h5f object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d53328ae-2714-462e-80af-a9f987a065eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5f.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3033de3-4841-4b6e-a84b-de300aadc4d6",
   "metadata": {},
   "source": [
    "This line retrieves the keys of the datasets stored in the opened HDF5 file (h5f).  \n",
    "The keys() method returns a list-like object containing the names of all top-level datasets or groups within the HDF5 file.  \n",
    "These keys represent the various datasets or collections of data stored in the file, allowing you to identify what information is available for further access or manipulation.  \n",
    "By examining these keys, you can determine the structure of the data and decide which datasets to load or analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d6d2fcd8-7e02-4447-a80c-ac35d8f042ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=h5f['X_train'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6839581b-8c14-4e10-b91f-ab0ec8a57aca",
   "metadata": {},
   "source": [
    "This line retrieves the dataset named 'X_train' from the opened HDF5 file (h5f) and assigns it to the variable X_train.  \n",
    "The expression h5f['X_train'] accesses the specific dataset within the file, and the [:] syntax is used to load all the data from that dataset into memory.  \n",
    "X_train is likely to contain the training data, possibly images or features related to the autonomous vehicle dataset.  \n",
    "By storing it in the X_train variable, you can now manipulate or analyze this data in your program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b8a12e40-c828-4198-94a9-49d23b9e38c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=h5f['y_train'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d40bf7-0b37-4a7a-bcf5-5d13ca9187d1",
   "metadata": {},
   "source": [
    "This line retrieves the dataset named 'y_train' from the opened HDF5 file (h5f) and assigns it to the variable y_train.  \n",
    "Similar to the previous line, h5f['y_train'] accesses the specific dataset within the file, and the [:] syntax is used to load all the data from that dataset into memory.  \n",
    "y_train is likely to contain the corresponding labels or targets for the training data, which are essential for supervised learning tasks.  \n",
    "By storing it in the y_train variable, you can use this label information in conjunction with X_train for training machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9cdf7019-820c-4932-82ef-112d455e4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=h5f['X_test'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff732969-e8fa-4371-b8e8-67c041dc1448",
   "metadata": {},
   "source": [
    "This line retrieves the dataset named 'X_test' from the opened HDF5 file (h5f) and assigns it to the variable X_test.  \n",
    "Just like in the previous lines, h5f['X_test'] accesses the specific dataset, and the [:] syntax loads all the data from that dataset into memory.  \n",
    "X_test is likely to contain the testing data, which may consist of images or features that will be used to evaluate the performance of a model after it has been trained.  \n",
    "By storing this data in the X_test variable, you can use it to assess how well your model generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "84052e5c-6c61-42c9-a4f9-4f68a25e78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=h5f['y_test'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d14496-9471-4d9d-ac31-828846b408d7",
   "metadata": {},
   "source": [
    "This line retrieves the dataset named 'y_test' from the opened HDF5 file (h5f) and assigns it to the variable y_test.  \n",
    "As with the previous lines, h5f['y_test'] accesses the specific dataset, and the [:] syntax loads all the data from that dataset into memory.  \n",
    "y_test is likely to contain the labels or targets corresponding to the testing data, which are necessary for evaluating the model’s accuracy and performance on unseen data.  \n",
    "By storing this information in the y_test variable, you can compare the model's predictions against these true labels during the testing phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ddb26964-32e1-4692-8e6a-9a8856ef7eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a7586c-b4bd-4738-969f-e2f017885de6",
   "metadata": {},
   "source": [
    "This line retrieves the shape of the X_train array, which contains the training data.  \n",
    "The shape attribute returns a tuple representing the dimensions of the array. For example, if X_train contains images, the shape might indicate the number of images and their dimensions (e.g., number of samples, height, width, channels).  \n",
    "Understanding the shape of X_train is crucial for confirming that the data is formatted correctly for further processing or input into machine learning models. It helps ensure that the number of samples matches the expected input size for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ab553ab0-9021-4931-97b3-2e3c251d27bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 32, 32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d92a4a-228f-4ee0-9f52-732ff1d9c4a1",
   "metadata": {},
   "source": [
    "This line retrieves the shape of the X_test array, which contains the testing data.  \n",
    "The shape attribute returns a tuple that indicates the dimensions of the array. For instance, if X_test consists of images, the shape may reflect the number of test images along with their respective dimensions (e.g., number of samples, height, width, channels).  \n",
    "Checking the shape of X_test is important to ensure that the test data is structured correctly and that it aligns with the input requirements of the model you plan to evaluate. This helps verify that the model can appropriately process the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "56916cd2-e5c0-4fb5-a4e7-650f7544faab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbce3ed-bafe-41a8-bed6-f1312a6190c0",
   "metadata": {},
   "source": [
    "This line retrieves the shape of the y_train array, which contains the labels or targets corresponding to the training data.  \n",
    "The shape attribute returns a tuple that indicates the dimensions of the array. For example, if y_train consists of labels for a classification task, its shape might reflect the number of training samples (e.g., the number of labels corresponding to the images in X_train).  \n",
    "Understanding the shape of y_train is essential for confirming that it matches the number of samples in X_train, ensuring that the labels are correctly associated with their corresponding data for training a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "62229219-d9af-4508-adbb-370dd4380977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e75dbe-1dee-4ba3-b88b-0b307584a8c9",
   "metadata": {},
   "source": [
    "This line retrieves the shape of the y_test array, which contains the labels or targets corresponding to the testing data.  \n",
    "The shape attribute returns a tuple indicating the dimensions of the array. For instance, if y_test consists of labels for a classification task, its shape will typically reflect the number of test samples (i.e., the number of labels associated with the images in X_test).  \n",
    "Understanding the shape of y_test is crucial for confirming that it aligns with the number of samples in X_test, ensuring that the labels correspond correctly to the data used for evaluating the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a5a4d6f6-110b-4343-a534-ba4c45b4ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_lab(n):\n",
    " plt.figure(figsize=(n,1))\n",
    " for i in range(n):\n",
    "  plt.subplot(1,n,i+1)\n",
    "  plt.imshow(X_train[i],cmap='gray')\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "  print('label for each of the above image:%s'%(y_train[0:n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83803cf1-4d0f-40ac-99bb-6ea425615e90",
   "metadata": {},
   "source": [
    "This function, img_lab(n), is designed to display a specified number (n) of images from the X_train dataset along with their corresponding labels. \n",
    "\n",
    "1. plt.figure(figsize=(n, 1)): This line creates a new figure for the plot with a width of n inches and a height of 1 inch, allowing for a horizontal arrangement of images.\n",
    "\n",
    "2. for i in range(n): This loop iterates n times, enabling the display of n images.\n",
    "\n",
    "3. plt.subplot(1, n, i + 1): This line sets up a subplot grid with 1 row and n columns, positioning the current image in the i + 1 slot.\n",
    "\n",
    "4. plt.imshow(X_train[i], cmap='gray'): This line displays the i-th image from X_train using a grayscale colormap.\n",
    "\n",
    "5. plt.axis('off'): This line hides the axis ticks and labels for a cleaner display of the images.\n",
    "\n",
    "6. plt.show(): This line renders the images on the screen after the loop is completed.\n",
    "\n",
    "7. print('label for each of the above image: %s' % (y_train[0:n])): After displaying the images, this line prints the labels for the first n images, showing the corresponding labels from the y_train dataset.\n",
    "\n",
    "Overall, the function is useful for visualizing a batch of training images alongside their labels, making it easier to understand the data being used for training a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0a29bf02-0e6d-4357-91ed-5f69038db301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image:[2 6 7 4 4 0 3 0 7 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image:[2 6 7 4 4 0 3 0 7 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image:[2 6 7 4 4 0 3 0 7 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image:[2 6 7 4 4 0 3 0 7 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image:[2 6 7 4 4 0 3 0 7 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image:[2 6 7 4 4 0 3 0 7 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image:[2 6 7 4 4 0 3 0 7 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image:[2 6 7 4 4 0 3 0 7 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image:[2 6 7 4 4 0 3 0 7 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image:[2 6 7 4 4 0 3 0 7 3]\n"
     ]
    }
   ],
   "source": [
    "img_lab(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769933ab-41bc-4529-966c-dc683b93a191",
   "metadata": {},
   "source": [
    "This line calls the function img_lab with an argument of 10, which instructs the function to display 10 images from the X_train dataset along with their corresponding labels.\n",
    "\n",
    "1. Image Display: The function will create a figure that arranges 10 images horizontally. Each image displayed corresponds to the first 10 entries in the X_train dataset.\n",
    "\n",
    "2. Labels Output: After displaying the images, the function will print the labels for these 10 images from the y_train dataset, providing a clear reference to the true classifications for each displayed image.\n",
    "\n",
    "This call is particularly useful for quickly visualizing a sample of training data and checking whether the images and their associated labels are correctly aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1fbdad14-9974-402b-a026-ac39d7048450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba64e8d-8c00-4c02-9e40-c5ec20ba2495",
   "metadata": {},
   "source": [
    "This line retrieves the shape of the X_train array, which contains the training data.  \n",
    "The shape attribute returns a tuple indicating the dimensions of the array. For example, if X_train contains images, the shape might specify the number of training samples and the dimensions of each image (e.g., number of samples, height, width, channels).  \n",
    "Understanding the shape of X_train is important to confirm that the data is structured correctly for further processing or input into machine learning models. It ensures that the number of samples aligns with what is expected for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fc0f63cb-e3f1-4adc-93a1-bb7c065b35c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(X_train.shape[0],1024,1)\n",
    "X_test=X_test.reshape(X_test.shape[0],1024,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef95b9-128a-402d-bf44-89bdca6d9eb7",
   "metadata": {},
   "source": [
    "These lines reshape the X_train and X_test arrays to prepare them for input into machine learning models.\n",
    "\n",
    "X_train.reshape(X_train.shape[0], 1024, 1):\n",
    "\n",
    "This line reshapes the X_train array.\n",
    "X_train.shape[0] represents the number of samples (images) in the training dataset.\n",
    "The new shape will be (number of samples, 1024, 1), where 1024 could represent the flattened pixel values of each image (assuming the original images were 32x32 pixels, which equals 1024) and 1 indicates a single channel (grayscale).\n",
    "This transformation is often necessary for models that expect input in a specific dimensional format.\n",
    "X_test.reshape(X_test.shape[0], 1024, 1):\n",
    "\n",
    "Similarly, this line reshapes the X_test array in the same manner.\n",
    "The shape will also be (number of samples, 1024, 1), ensuring that the test data has the same dimensions as the training data.\n",
    "Reshaping the arrays in this way standardizes the input format, making it compatible with many deep learning frameworks that require a specific input shape, especially when dealing with convolutional neural networks (CNNs) or other models expecting multi-dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "817feb60-c2d4-4ece-8d89-de848ba8f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d613bdb6-40cd-4c00-91c6-540df348997e",
   "metadata": {},
   "source": [
    "1. X_train = X_train / 255.0:\n",
    "   - This line divides all pixel values in the X_train array by 255.0, which is the maximum value for pixel intensity in an 8-bit grayscale image. \n",
    "   - Normalization rescales the pixel values to a range between 0 and 1, making the data more suitable for training machine learning models. \n",
    "   - This helps improve the convergence speed and overall performance of algorithms like neural networks.\n",
    "\n",
    "2. X_test = X_test / 255.0:\n",
    "   - Similarly, this line normalizes the pixel values in the X_test array by dividing by 255.0.\n",
    "   - It ensures that the test data is scaled in the same way as the training data, which is essential for maintaining consistency in how the model interprets both datasets during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9b632882-35e8-48aa-8553-e02c7b1780e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized Training set (42000, 1024, 1) (42000,)\n",
      "Resized Test set (18000, 1024, 1) (18000,)\n"
     ]
    }
   ],
   "source": [
    "print('Resized Training set',X_train.shape,y_train.shape)\n",
    "print('Resized Test set',X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72326ea2-7531-4f70-8c28-9b8e4c446aa6",
   "metadata": {},
   "source": [
    "1. print('Resized Training set', X_train.shape, y_train.shape):\n",
    "   - This line outputs the message \"Resized Training set\" followed by the shapes of the X_train and y_train arrays.\n",
    "   - X_train.shape provides the dimensions of the training data, indicating the number of training samples, the image size (e.g., height, width), and the number of channels.\n",
    "   - y_train.shape shows the dimensions of the labels, which typically indicates the number of labels corresponding to the training samples.\n",
    "   - This helps verify that the training data and labels are aligned correctly after resizing.\n",
    "\n",
    "2. print('Resized Test set', X_test.shape, y_test.shape):\n",
    "   - Similarly, this line outputs the message \"Resized Test set\" followed by the shapes of the X_test and y_test arrays.\n",
    "   - X_test.shape provides the dimensions of the test data, while y_test.shape indicates the dimensions of the test labels.\n",
    "   - This ensures that the test data and labels are also aligned correctly and confirms that both datasets are properly prepared for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1e7b7d7c-e06e-4c6f-ada1-df72c78b2a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THe number of classes in this dataset are: 10\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    " #one hot encode outputs\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    " #no. of classes\n",
    "num_classes=y_test.shape[1]\n",
    "print('THe number of classes in this dataset are:',num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2893c09-8563-4a34-86a8-73493db005cd",
   "metadata": {},
   "source": [
    "1. from tensorflow.keras.utils import to_categorical:\n",
    "   - This line imports the to_categorical function from TensorFlow's Keras utilities. This function is used for converting class labels to a one-hot encoded format, which is a common requirement for multi-class classification problems.\n",
    "\n",
    "2. y_train = to_categorical(y_train):\n",
    "   - This line applies one-hot encoding to the y_train array. \n",
    "   - Each label in y_train is transformed into a binary array where the index corresponding to the class is set to 1, and all other indices are set to 0. \n",
    "   - For example, if a label is 2 in a 5-class problem, it will be converted to [0, 0, 1, 0, 0].\n",
    "\n",
    "3. y_test = to_categorical(y_test):\n",
    "   - Similarly, this line applies one-hot encoding to the y_test array, converting the test labels into the same format as the training labels.\n",
    "\n",
    "4. num_classes = y_test.shape[1]:\n",
    "   - This line determines the number of classes in the dataset by checking the second dimension of the y_test array after one-hot encoding. \n",
    "   - The shape of y_test will now reflect the number of samples by the number of classes (e.g., if there are 5 classes, y_test.shape will be (number_of_samples, 5)).\n",
    "\n",
    "5. print('The number of classes in this dataset are:', num_classes):\n",
    "   - This line prints out the total number of classes identified in the dataset, providing a useful summary of the classification problem being addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cb94f5d7-0872-47da-b7c1-009daaa8e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d0098-5cd3-4aad-9aec-4fd7fbc772c5",
   "metadata": {},
   "source": [
    "- Purpose: The `to_categorical` function is used to convert class labels (which are typically integers representing the class of each sample) into a one-hot encoded format. One-hot encoding is a common technique in machine learning, especially for multi-class classification problems.  \n",
    "- Functionality: For example, if you have labels like `[0, 1, 2]` for a dataset with three classes, `to_categorical` will transform these labels into a format like `[[1, 0, 0], [0, 1, 0], [0, 0, 1]]`. Each label is represented as a binary vector where only the index corresponding to the class is set to 1, and all other indices are set to 0.  \n",
    "- Usage: This transformation is essential when training neural networks, as many loss functions (such as categorical cross-entropy) expect the target labels to be in one-hot encoded format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ec2e6cb1-8fff-4d64-bef1-1b4d7e3872b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6bd1b4-963d-4f98-bac5-d9367e849b24",
   "metadata": {},
   "source": [
    "  \n",
    "- Purpose: The `Sequential` class is used to create a linear stack of layers for building a neural network model. It is one of the simplest ways to define a model in Keras, allowing you to add layers sequentially, where the output of one layer becomes the input for the next.  \n",
    "- Functionality: When using `Sequential`, you can easily build models by adding layers one at a time using the `add()` method. For example, you might start with an input layer, followed by several hidden layers, and finish with an output layer.  \n",
    "- Usage: This class is particularly useful for straightforward architectures where each layer has a single input and output, such as feedforward neural networks and convolutional networks. However, for more complex architectures (like those involving multiple inputs, outputs, or shared layers), you might use the more flexible `Model` class instead.\n",
    "\n",
    "Overall, this import is a crucial step for defining and constructing a neural network model in Keras, facilitating the building of the architecture you need for your specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c858f247-08a4-42b8-94c8-817664f9f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8530fc-01b2-49a8-80b0-0d2bcfaae22e",
   "metadata": {},
   "source": [
    "1. `Conv2D`:\n",
    "   - This layer is used for applying a 2D convolution operation to the input, which is particularly useful for processing image data.\n",
    "   - It helps extract features from images by convolving filters (kernels) across the input data. Each filter learns to recognize specific patterns or features (like edges, textures, etc.).\n",
    "   - Typically, you specify the number of filters, the kernel size, the activation function, and other parameters.\n",
    "\n",
    "2. `MaxPooling2D`:\n",
    "   - This layer performs max pooling, which down-samples the input by taking the maximum value in a specified window (pooling region) for each patch of the input.\n",
    "   - It reduces the spatial dimensions (height and width) of the input, helping to decrease the computational load and extract dominant features while maintaining spatial hierarchy.\n",
    "\n",
    "3. `Flatten`:\n",
    "   - This layer flattens the input, converting it from a multi-dimensional tensor into a one-dimensional vector.\n",
    "   - It is typically used before fully connected (Dense) layers, allowing the output of the convolutional layers (which may be 2D) to be fed into these fully connected layers.\n",
    "\n",
    "4. `Dense`:\n",
    "   - This layer is a fully connected layer where each neuron is connected to every neuron in the previous layer.\n",
    "   - It is often used in the final layers of the network to produce the output (like class scores for classification tasks).\n",
    "   - You can specify the number of neurons and the activation function (like ReLU or softmax).\n",
    "\n",
    "5. `Dropout`:\n",
    "   - This layer is used for regularization during training to prevent overfitting.\n",
    "   - It randomly sets a fraction of the input units to 0 at each update during training time, which helps the model generalize better to unseen data.\n",
    "   - You can specify the dropout rate (the fraction of inputs to drop).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4018d42e-ebad-4dc0-9452-a437491b6ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a800648-8c43-4b1a-af69-a86e55832cd5",
   "metadata": {},
   "source": [
    "\n",
    "- Purpose: The Adam optimizer is a popular optimization algorithm used for training deep learning models. It combines the advantages of two other optimization algorithms: AdaGrad and RMSProp.\n",
    "  \n",
    "- Functionality: \n",
    "  - Adam maintains a learning rate for each parameter and adjusts it based on the first and second moments of the gradients (mean and uncentered variance). This allows it to adapt the learning rates dynamically during training, which can lead to faster convergence and better performance.\n",
    "  - It also includes momentum, which helps accelerate gradients in the right direction and smooths out the optimization path.\n",
    "\n",
    "- Usage: Adam is often the default choice for many types of neural networks due to its effectiveness and ease of use. You can specify hyperparameters such as the learning rate, beta values (for the moments), and epsilon (to prevent division by zero).\n",
    "\n",
    "Overall, importing the `Adam` optimizer is a crucial step for configuring your model's training process, as it determines how the model weights are updated during backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "af0a5c89-fb84-4abf-8d86-736a7f81cea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ad683-5354-4792-a45b-ac5e6e0911a6",
   "metadata": {},
   "source": [
    "- Purpose: The `Sequential` class is used to create a linear stack of layers for building a neural network model. It provides a straightforward way to construct models where each layer has exactly one input tensor and one output tensor.\n",
    "\n",
    "- Functionality:\n",
    "  - With the `Sequential` model, you can easily add layers one at a time using the `add()` method. This makes it simple to build architectures such as feedforward neural networks, convolutional neural networks (CNNs), and more.\n",
    "  - You can start with an input layer, add several hidden layers (like convolutional and pooling layers), and finish with an output layer (like a Dense layer).\n",
    "\n",
    "- Usage: The `Sequential` class is particularly useful for simple architectures, where the flow of data is linear from one layer to the next. However, for more complex architectures, such as those involving multiple inputs or outputs, you might use the more flexible Keras `Model` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "eb81781d-e12c-44d5-908b-c23ca64564c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b3bbe9-6165-4dc2-bc4b-ef494e0a7fbc",
   "metadata": {},
   "source": [
    "This line imports several layer classes from TensorFlow's Keras layers module, which are essential for building one-dimensional convolutional neural networks (1D CNNs). Here’s a brief overview of each imported layer:\n",
    "\n",
    "1. `Conv1D`:\n",
    "   - This layer applies a 1D convolution operation to the input data, making it suitable for processing sequential data, such as time series or sequences of words.\n",
    "   - It uses filters (kernels) that slide across the input data to extract features. Each filter learns to recognize specific patterns in the input sequences.\n",
    "\n",
    "2. `MaxPooling1D`:\n",
    "   - This layer performs max pooling on the input data to down-sample it.\n",
    "   - It reduces the dimensionality by taking the maximum value from specified regions (pooling windows) along the input sequence. This helps retain the most significant features while decreasing the amount of data and computational load.\n",
    "\n",
    "3. `Flatten`:\n",
    "   - This layer converts the multi-dimensional output from the previous layers into a one-dimensional vector.\n",
    "   - It is typically used before fully connected (Dense) layers, allowing the feature maps generated by convolutional layers to be fed into the Dense layers for classification.\n",
    "\n",
    "4. `Dense`:\n",
    "   - This layer is a fully connected layer where every neuron is connected to every neuron in the previous layer.\n",
    "   - It is often used in the final layers of the network to produce output, such as class scores in classification tasks. You can specify the number of neurons and the activation function (like ReLU or softmax).\n",
    "\n",
    "5. `Dropout`:\n",
    "   - This layer is used to prevent overfitting during training by randomly setting a fraction of the input units to zero at each update.\n",
    "   - This helps the model generalize better by reducing its dependency on specific neurons and forcing it to learn redundant representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "635d1f21-cc27-4aaf-9cd8-e5db10a0ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First convolutional layer\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(1024, 1)))  # Adjust input_shape as needed\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Third convolutional layer\n",
    "    model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Flatten the output for the dense layers\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Fully connected layer\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))  # Dropout for regularization\n",
    "    \n",
    "    # Output layer (adjust units based on the number of classes)\n",
    "    model.add(Dense(10, activation='softmax'))  # Assuming 10 classes for classification\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf8b52f-7313-4bb3-9eb4-61dc7f8e9747",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Function Definition: \n",
    "   - The `cnn_model()` function defines a convolutional neural network (CNN) architecture using the Sequential API from Keras. \n",
    "\n",
    "2. Creating the Model:\n",
    "   - `model = Sequential()`: Initializes an empty sequential model.\n",
    "\n",
    "3. First Convolutional Layer:\n",
    "   - `model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(1024, 1)))`: \n",
    "     - Adds a 1D convolutional layer with 32 filters and a kernel size of 3. \n",
    "     - The activation function is ReLU (Rectified Linear Unit).\n",
    "     - `input_shape=(1024, 1)` indicates that the input sequences have a length of 1024 with 1 feature (e.g., grayscale images or single-channel time series).\n",
    "   - `model.add(MaxPooling1D(pool_size=2))`: Adds a max pooling layer to down-sample the output by taking the maximum value in each pool of size 2.\n",
    "\n",
    "4. Second Convolutional Layer:\n",
    "   - `model.add(Conv1D(64, kernel_size=3, activation='relu'))`: Adds a second convolutional layer with 64 filters.\n",
    "   - `model.add(MaxPooling1D(pool_size=2))`: Adds another max pooling layer.\n",
    "\n",
    "5. Third Convolutional Layer:\n",
    "   - `model.add(Conv1D(128, kernel_size=3, activation='relu'))`: Adds a third convolutional layer with 128 filters.\n",
    "   - `model.add(MaxPooling1D(pool_size=2))`: Adds a third max pooling layer.\n",
    "\n",
    "6. Flattening:\n",
    "   - `model.add(Flatten())`: Flattens the 3D output of the last convolutional layer into a 1D vector to prepare it for the fully connected layers.\n",
    "\n",
    "7. Fully Connected Layer:\n",
    "   - `model.add(Dense(128, activation='relu'))`: Adds a fully connected (dense) layer with 128 neurons and ReLU activation.\n",
    "   - `model.add(Dropout(0.5))`: Adds a dropout layer with a dropout rate of 0.5 to reduce overfitting.\n",
    "\n",
    "8. Output Layer:\n",
    "   - `model.add(Dense(10, activation='softmax'))`: Adds the output layer with 10 neurons (assuming 10 classes for classification) and softmax activation. This layer outputs the probabilities of each class.\n",
    "\n",
    "9. Return Model:\n",
    "   - The function returns the constructed model, which can then be compiled and trained on the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0614f724-6bd8-4f7a-b485-dd967dad736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=cnn_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcbea76-1c69-4f71-b591-125060871a08",
   "metadata": {},
   "source": [
    "The line `model = cnn_model()` calls the previously defined `cnn_model()` function to create a convolutional neural network (CNN) architecture. This function initializes a Sequential model and adds multiple layers, including convolutional, pooling, flattening, and fully connected layers. The resulting model structure is designed to process one-dimensional data effectively. The model is then assigned to the variable `model`, making it ready for compilation, training, and evaluation on a dataset. This step is crucial for setting up the deep learning framework needed for further tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f159de06-dfde-43a3-b893-fbfe8341dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = cnn_model()\n",
    "\n",
    "# Compile the model with the correct learning_rate argument\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c92f64c-c45b-457e-80ec-00acf065cfd2",
   "metadata": {},
   "source": [
    "1. Creating the Model:\n",
    "   - `model = cnn_model()`: This line calls the `cnn_model()` function to create a new convolutional neural network (CNN) architecture, which is then assigned to the variable `model`.\n",
    "\n",
    "2. Compiling the Model:\n",
    "   - `model.compile(...)`: This line configures the model for training by specifying the optimizer, loss function, and metrics to evaluate.\n",
    "   - Optimizer: `optimizer=Adam(learning_rate=1e-3)`: The Adam optimizer is instantiated with a learning rate of \\(1 \\times 10^{-3}\\), which determines how quickly the model updates its weights during training.\n",
    "   - Loss Function: `loss='categorical_crossentropy'`: This specifies the loss function used to evaluate the model's performance; categorical cross-entropy is suitable for multi-class classification problems where the target labels are one-hot encoded.\n",
    "   - Metrics: `metrics=['accuracy']`: This sets the metric to track during training and evaluation; in this case, it tracks the accuracy of the model's predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e41084-11b6-4c34-98ee-36a0b656b83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 56ms/step - accuracy: 0.2856 - loss: 1.9660 - val_accuracy: 0.6239 - val_loss: 1.2084\n",
      "Epoch 2/5\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 57ms/step - accuracy: 0.5420 - loss: 1.3619 - val_accuracy: 0.6639 - val_loss: 1.0712\n",
      "Epoch 3/5\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 63ms/step - accuracy: 0.5793 - loss: 1.2503 - val_accuracy: 0.6831 - val_loss: 1.0049\n",
      "Epoch 4/5\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 54ms/step - accuracy: 0.5952 - loss: 1.1841 - val_accuracy: 0.6839 - val_loss: 1.0010\n",
      "Epoch 5/5\n",
      "\u001b[1m1173/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.6078 - loss: 1.1553"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "training_history = model.fit(X_train, y_train, \n",
    "                              validation_data=(X_test, y_test), \n",
    "                              epochs=5,       # Adjust the number of epochs as needed\n",
    "                              batch_size=32,   # Adjust the batch size as needed\n",
    "                              verbose=1)      # You can set verbose=2 for more detailed output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226dd8e6-c711-41ef-8ddd-6f535e08190a",
   "metadata": {},
   "source": [
    "1. Fitting the Model:\n",
    "   - `training_history = model.fit(...)`: This line trains the previously compiled CNN model using the training data (`X_train` and `y_train`) and stores the training history in the variable `training_history`.\n",
    "\n",
    "2. Training Data and Validation Data:\n",
    "   - `X_train, y_train`: These are the input features and labels for training.\n",
    "   - `validation_data=(X_test, y_test)`: This argument specifies the validation dataset used to evaluate the model's performance after each epoch. The validation data helps monitor overfitting during training.\n",
    "\n",
    "3. Epochs:\n",
    "   - `epochs=5`: This sets the number of complete passes through the training dataset. You can adjust this value depending on how well the model is learning and if it's converging.\n",
    "\n",
    "4. Batch Size:\n",
    "   - `batch_size=32`: This determines the number of samples processed before the model's weights are updated. A smaller batch size can provide more updates per epoch, while a larger batch size may lead to faster computation but less frequent updates.\n",
    "\n",
    "5. Verbose Level:\n",
    "   - `verbose=1`: This controls the output of the training process. Setting it to 1 provides a progress bar and logs the loss and accuracy for each epoch. If set to 2, it will provide more detailed output, displaying the metrics for each epoch without a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa1658-cb04-4d89-88ce-be3a9a05a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=model.evaluate(X_test,y_test,verbose=0)\n",
    " print('Loss:',scores[0])\n",
    " print('Accuracy:',scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597f498a-42ae-4ea7-a64f-3763a1dd86b6",
   "metadata": {},
   "source": [
    "1. Evaluating the Model:\n",
    "   - `scores = model.evaluate(X_test, y_test, verbose=0)`: This line evaluates the trained model on the test dataset (`X_test` and `y_test`). The `evaluate` method returns the loss value and any additional metrics specified during model compilation.\n",
    "   - The `verbose=0` argument suppresses output during evaluation, so the function runs quietly without displaying progress.\n",
    "\n",
    "2. Loss and Accuracy:\n",
    "   - `scores[0]`: This retrieves the first value from the `scores` list, which corresponds to the loss of the model on the test data. The loss indicates how well the model's predictions match the actual labels, with lower values indicating better performance.\n",
    "   - `scores[1]`: This retrieves the second value from the `scores` list, which represents the accuracy of the model on the test data. Accuracy measures the proportion of correctly predicted instances out of the total instances.\n",
    "\n",
    "3. Printing Results:\n",
    "   - `print('Loss:', scores[0])`: This line prints the loss value to the console.\n",
    "   - `print('Accuracy:', scores[1])`: This line prints the accuracy value to the console.\n",
    "\n",
    "Overall, this code evaluates the performance of the trained model on unseen test data, providing important metrics (loss and accuracy) that indicate how well the model generalizes to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f374bc-d540-43e4-bbf2-19af12089c86",
   "metadata": {},
   "outputs": [],
   "source": [
    " accuracy=training_history.history['accuracy']\n",
    " val_accuracy=training_history.history['val_accuracy']\n",
    " loss=training_history.history['loss']\n",
    " val_loss=training_history.history['val_loss']\n",
    " epochs=range(len(accuracy))\n",
    " plt.plot(epochs,accuracy,label='training accuracy')\n",
    " plt.plot(epochs,val_accuracy,label='validation accuracy')\n",
    " plt.title('Training and validation accuracy')\n",
    " plt.legend(loc='lower right')\n",
    " plt.figure()\n",
    " plt.plot(epochs,loss,label='training loss')\n",
    " plt.plot(epochs,val_loss,label='validation loss')\n",
    " plt.legend(loc='upper right')\n",
    " plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791748d5-fea9-47e0-9c0a-1a25009dd748",
   "metadata": {},
   "source": [
    "1. Extracting History Data:\n",
    "   - `accuracy = training_history.history['accuracy']`: This line extracts the training accuracy values from the training history returned by the `fit` method.\n",
    "   - `val_accuracy = training_history.history['val_accuracy']`: This extracts the validation accuracy values, which show how the model performs on the validation set after each epoch.\n",
    "   - `loss = training_history.history['loss']`: This retrieves the training loss values.\n",
    "   - `val_loss = training_history.history['val_loss']`: This retrieves the validation loss values.\n",
    "\n",
    "2. Defining Epochs:\n",
    "   - `epochs = range(len(accuracy))`: This creates a range object representing the number of epochs based on the length of the accuracy list. It will be used for the x-axis of the plots.\n",
    "\n",
    "3. Plotting Accuracy:\n",
    "   - `plt.plot(epochs, accuracy, label='training accuracy')`: This plots the training accuracy against the epochs.\n",
    "   - `plt.plot(epochs, val_accuracy, label='validation accuracy')`: This plots the validation accuracy against the epochs.\n",
    "   - `plt.title('Training and Validation Accuracy')`: This sets the title for the accuracy plot.\n",
    "   - `plt.legend(loc='lower right')`: This adds a legend to the plot to identify the training and validation accuracy lines.\n",
    "\n",
    "4. Creating a New Figure for Loss:\n",
    "   - `plt.figure()`: This creates a new figure for plotting the loss values, separating it from the accuracy plot.\n",
    "\n",
    "5. Plotting Loss:\n",
    "   - `plt.plot(epochs, loss, label='training loss')`: This plots the training loss against the epochs.\n",
    "   - `plt.plot(epochs, val_loss, label='validation loss')`: This plots the validation loss against the epochs.\n",
    "   - `plt.legend(loc='upper right')`: This adds a legend to the loss plot.\n",
    "   - `plt.title('Training and Validation Loss')`: This sets the title for the loss plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef682449-57f6-4823-a278-d4c6d427f323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
